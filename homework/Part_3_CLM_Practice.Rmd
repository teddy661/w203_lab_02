<<<<<<< HEAD
---
title: "Part_3: CLM Practice"
author: 'The Principal Components'
output: pdf_document
---

```{r setup, include=FALSE, echo=FALSE, warning=FALSE, message=FALSE}
knitr::opts_chunk$set(echo = TRUE)

```

```{r}
library(tidyverse) 
library(stargazer)
library(sandwich)
library(lmtest)
library(dplyr)

```
```{r load data}
?read.delim
video <- read.delim('videos.txt', header=TRUE, sep='\t', dec = ".", na.strings = "NA")
head(video)
nrow(video)
ncol(video)
```
```{r}
video <- video %>% 
  mutate(ln_views = log(views)) %>% drop_na(rate,length)

```

```{r warning=FALSE, out.height= 100%, out.width=100%}
# To assemble multiple plots
library(gridExtra)

p1 <- ggplot(data = video, aes(x = video$rate)) +
  geom_histogram(bins = 30) +
  scale_x_continuous(breaks = seq(0,20,5))+
  labs(title = "Histogram of Rate",x = "Rate",y = "Count")


p2 <- ggplot(data = video, aes(x = video$length)) +
  geom_histogram(bins = 30) +
  scale_x_continuous(breaks = seq(0,30,2))+
  labs(title = "Histogram of Views ", x = "Views", y = "Count")


p3 <- ggplot(data = video, aes(x = video$rate, y = video$ln_views)) +
  geom_point() +
  geom_smooth(se = FALSE) +
  labs(title = "Association between log Views and Rate", x = "Rate", y = "Log Views")


p4 <- ggplot(data = video, aes(x = video$length, y = video$ln_views)) +
  geom_point() +
  geom_smooth(se = FALSE) +
  labs(title = "Association between log Views and Length", x = "Rate", y = "Log Views")

grid.arrange(p1, p2,p3,p4, nrow = 2, ncol = 2)
```


## Part 2 - CLM Practice

For the following questions, your task is to evaluate the Classical Linear Model assumptions. It is not enough to say that an assumption is met or not met; instead, present evidence based on your background knowledge, visualizations, and numerical summaries.

The file `videos.txt` contains 9618 observations of videos shared on YouTube. It was created by Cheng, Dale and Liu at Simon Fraser University. Please see [this link](http://netsg.cs.sfu.ca/youtubedata/) for details about how the data was collected.

You wish to run the following regression:

$$
ln(\text{views}) = \beta_0 + \beta_1 \text{rate}  + \beta_3 \text{length}
$$ 
The variables are as follows:

- `views`: the number of views by YouTube users.
- `rate`: This is the average of the ratings that the video received. You may think of this as a proxy for video quality. (Notice that this is different from the variable `ratings` which is a count of the total number of ratings that a video has received.)
- `length:` the duration of the video in seconds.


```{r linear regression}
lm_video <- lm(ln_views ~ rate + length, data = video)

#check on Robust Standard Error
ses = diag(vcovHC(lm_video))^0.5
#stargazer doesn't correct for robust errors by default;set se=ses to override with the robust errors
stargazer(lm_video, type = 'text', title = "Video Views Model",
          se = list(ses), omit.stat = "f", star.cutoffs = c(0.05, 0.01, 0.001),
          digits = 4, out="table1.txt")
```


1. Evaluate the **IID** assumption.
The list of video contains videos sampled from YouTube using a crawling algorithm in which it starts with a set of  videos from the list of "Recently Featured", "Most Viewed", "Top Rated" and "Most Discussed", for "Today", "This Week", "This Month" and "All Time" and then the algorithm uses this list to find more related videos. We argue that the initial set of videos are not independently sampled. For example, if the sample time frame is around election time, we would expect that "Recently Featured" or “Most Discussed” videos are more likely to related to the topic of election for “Today” or “This Week.”. In addition, the crawl algorithm is adding videos into the list by finding videos that are directly related the initial set of videos. Therefore, by the nature of the sampling process, the videos in the list are NOT IID but related to each other.

2. Evaluate the **No perfect Colinearity** assumption.
We can look at the coefficents of the model.  

```{r}
lm_video$coefficients
```
We see that R has not rate or length variable in the model which means that there is no perfect colinearity. 


In addition, we can also to assess the **No perfect colinearity** assumption by look at the scatter plot of these two variables to see if there is any obvious linear relationship. Thirdly, we can compute the correlation between these two variable using Pearson's correlation method.

```{r}

ggplot(data = video, aes(x = video$rate, y = video$length)) +
  geom_point() +
  geom_smooth(se = FALSE) +
  labs(title = "Relationshiop between video's rate and length", x = "Video's Rate", y = "Video's Length")



cor.test(video$rate, video$length, method = "pearson")

```
The scatter plot above shows that rate and length has no obvious relationship. In addition, the correlation test results shows that the estimate correlation between rate and length is 0.156 (CI: 0.1372389 0.1762458, p = 2.2e-16). Thus, we can say that there is obvious problem with the **No perfect Colinearity** assumption.

3. Evaluate the **Linear Conditional Expectation:** assumption. 

```{r}
video <- video %>% mutate(
  lm_video_predictions = predict(lm_video),
  lm_video_residuals = resid(lm_video)
)

plot_rate_vs_residuals <- video %>% ggplot(aes(x = rate, y = lm_video_residuals))+
  geom_point() + stat_smooth() + labs( title = "residuals with respect to rate")

plot_length_vs_residuals <- video %>% ggplot(aes(x = length, y = lm_video_residuals))+
  geom_point() + stat_smooth() + labs( title = "residuals with respect to length")

plot_prediction_vs_residuals <- video %>% ggplot(aes(x = lm_video_predictions, y = lm_video_residuals))+
  geom_point() + stat_smooth() + labs( title = "residuals with respect to prediction")

plot_rate_vs_residuals
plot_length_vs_residuals
plot_prediction_vs_residuals


```

Looking at the lot of residual versus rate above, we see that the line of residual average is somewhat oscillating around zero. However, the line of of residual versus length has a downward curvature as length increases. This means that there is non-linear relationship between the outcome variable (log(views)) and the regressor (length). This non-linear relationship is likey causing the line of residual versus predicted values to curve downward as the value of predictions grew large. Therefore, the linear condition expectation is not a safe assumption and thus linear model is likely not the best model to predict video’s views based on rate and length. 

4. Evaluate the **Homoskedastic Errors:** assumption.

```{r plotting prediction versus residuals}

plot_prediction_vs_residuals

lmtest::bptest(lm_video)

```
From the residuals versus fitted values plot above, we see that as we are going from prediction with low values of 5 to high values of 8, the residuals increase. Additionally, we can use the Breusch-Pagan test where the null hypothesis is that homoscedasticity is present to evaluate our assumption. The test results in BP of 128.39 with p values of < 2.2e-16 which means that we can reject the null hypothesis. Therefore, we can conclude that heteroscedascity is present in the regression model.


5. Evaluate the **Normally Distributed Errors:** assumption.

```{r q-q plot of residuals}
plot_1 <- video %>% ggplot(aes(x=lm_video_residuals)) + geom_histogram()
plot_2 <- video %>% ggplot(aes(sample=lm_video_residuals)) + stat_qq() +stat_qq_line()

plot_1
plot_2

```


From the histogram and Q-Q plots of residual above showed that standard errors are fairly normally distributed. Thus we can say that there is no problem with the **Normally Distributed Errors:** assumption. 

